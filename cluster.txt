import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
from scipy.cluster.hierarchy import linkage, dendrogram

df = pd.read_csv("D:\\DS_Model\\DS_exp\\wine-clustering.csv")
print("Dataset preview:")
print(df.head())

features = [
    "Alcohol", "Malic_Acid", "Ash", "Ash_Alcanity", "Magnesium", "Total_Phenols",
    "Flavanoids", "Nonflavanoid_Phenols", "Proanthocyanins", "Color_Intensity",
    "Hue", "OD280", "Proline"
]
scaler = StandardScaler()
X = scaler.fit_transform(df[features])

sse = []
k_range = range(2, 11)
for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X)
    sse.append(kmeans.inertia_)

plt.figure(figsize=(8, 5))
plt.plot(k_range, sse, marker='o')
plt.title('Elbow Method: Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Sum of Squared Errors (Inertia)')
plt.grid(True)
plt.show()

k = 3
kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
cluster_labels_kmeans = kmeans.fit_predict(X)

df['ClusterLabel_KMeans'] = cluster_labels_kmeans

inertia = kmeans.inertia_
silhouette_avg = silhouette_score(X, cluster_labels_kmeans)
davies_bouldin = davies_bouldin_score(X, cluster_labels_kmeans)
calinski_harabasz = calinski_harabasz_score(X, cluster_labels_kmeans)

print(f"\nEvaluation Metrics (k={k}):")
print(f"Inertia (SSE): {inertia:.4f}")
print(f"Silhouette Score: {silhouette_avg:.4f}")
print(f"Davies-Bouldin Index: {davies_bouldin:.4f}")
print(f"Calinski-Harabasz Score: {calinski_harabasz:.4f}")

print("\nCluster distribution:")
print(df['ClusterLabel_KMeans'].value_counts())

print("\nCluster-wise Feature Averages:")
print(df.groupby('ClusterLabel_KMeans')[features].mean())

dbscan = DBSCAN(eps=0.8, min_samples=5)
cluster_labels_dbscan = dbscan.fit_predict(X)
df['DBSCAN_Cluster'] = cluster_labels_dbscan

agglo = AgglomerativeClustering(n_clusters=5)
cluster_labels_agglo = agglo.fit_predict(X)
df['Agglo_Cluster'] = cluster_labels_agglo

linked = linkage(X, method='ward')
plt.figure(figsize=(10, 7))
dendrogram(linked)
plt.title('Hierarchical Clustering Dendrogram')
plt.show()

if len(set(df['DBSCAN_Cluster'])) > 1 and -1 not in set(df['DBSCAN_Cluster']):
    print("DBSCAN Silhouette Score:", silhouette_score(X, cluster_labels_dbscan))
else:
    print("DBSCAN: Not applicable")

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

plt.figure(figsize=(8, 6))
scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels_kmeans, cmap='viridis', s=20, alpha=0.8)
plt.title('2D PCA Projection of K-Means Clusters')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.grid(True)
plt.colorbar(scatter, label='Cluster')
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 6))
scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels_dbscan, cmap='viridis', s=20, alpha=0.8)
plt.title('2D PCA Projection of DBSCAN Clusters')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.grid(True)
plt.colorbar(scatter, label='Cluster')
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 6))
scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels_agglo, cmap='viridis', s=20, alpha=0.8)
plt.title('2D PCA Projection of Agglomerative Clusters')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.grid(True)
plt.colorbar(scatter, label='Cluster')
plt.tight_layout()
plt.show()